{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nbH8DiPfnFo"
   },
   "source": [
    "# Image Classification - The Multi-class Weather Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_eFY2j9fnFw"
   },
   "source": [
    "## Data exploration, preparation, and partition\n",
    "\n",
    "Please start by downloading the Mendeley Weather Dataset (MWD) from the following link and unzip it:\n",
    "\n",
    "https://data.mendeley.com/datasets/4drtyfjtfy/1\n",
    "\n",
    "Once unzipped, you’ll find the dataset contains 1,125 images representing various weather conditions. Ensure these images are placed in a folder named dataset2, located in the same directory as your Jupyter notebook.\n",
    "\n",
    "Create three CSV files—my_training.csv, my_validation.csv, and my_test.csv—to split the dataset into training, validation, and test sets. Each CSV file should include the following columns:\n",
    "\n",
    "- File path\n",
    "- Image label\n",
    "\n",
    "Ensure that the dataset is divided randomly to maintain a uniform distribution of labels across each set. The entries should be sorted randomly.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_tuner import RandomSearch, HyperParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_xs5_xhfnFy"
   },
   "source": [
    "#### 1.1.2 Extracting file paths and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we prepares an image dataset by iterating through files in dataset2, extracting labels from file names, and storing both file paths and labels in a pandas DataFrame. We construct full file paths, extracts text labels while removing digits and trailing spaces, and populates lists with these paths and labels. Finally, we create a DataFrame with two columns for file paths and labels for further processing of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing lists to hold paths and labels\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "# Loop through each file in dataset2 \n",
    "for file_name in os.listdir('dataset2'):\n",
    "    if file_name.endswith('.jpg'):\n",
    "        \n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join('dataset2', file_name)\n",
    "        \n",
    "        # Extract the label from the file name by \n",
    "        \n",
    "        label = file_name.split('.')[0]   # removing all after dot\n",
    "        label = ''.join([i for i in label if not i.isdigit()]).rstrip()  # removing whitespace after lables\n",
    "        \n",
    "        file_paths.append(file_path)\n",
    "        labels.append(label)\n",
    "\n",
    "# Creating our DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'File path': file_paths,\n",
    "    'Image label': labels\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3 Making random partitions with similar distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we Split the dataset into training, validation, and test sets for effective training, tuning, and evaluation of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Split the dataset into training (60%), validation (20%), and test sets (20%)\n",
    "train, temp = train_test_split(data, test_size=0.4, stratify=data['Image label']) # Training and Temporary Set\n",
    "validation, test = train_test_split(temp, test_size=0.5, stratify=temp['Image label']) # Validation and Test Set\n",
    "\n",
    "# Save the partitions to their corresponding CSV files\n",
    "train.to_csv('my_training.csv', index=False, header=False)\n",
    "validation.to_csv('my_validation.csv', index=False, header=False)\n",
    "test.to_csv('my_test.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4 Data Partitioning Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compare our results with the given dataset to ensure consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Distribution in Training Set:\n",
      "sunrise    0.316493\n",
      "cloudy     0.267459\n",
      "shine      0.225854\n",
      "rain       0.190193\n",
      "Name: Image label, dtype: float64 \n",
      "\n",
      "\n",
      "First 10 Rows of Training Set:\n",
      "                 File path Image label\n",
      "0      dataset2/rain43.jpg        rain\n",
      "1   dataset2/cloudy211.jpg      cloudy\n",
      "2     dataset2/rain152.jpg        rain\n",
      "3    dataset2/shine224.jpg       shine\n",
      "4   dataset2/sunrise57.jpg     sunrise\n",
      "5   dataset2/sunrise85.jpg     sunrise\n",
      "6  dataset2/sunrise144.jpg     sunrise\n",
      "7    dataset2/shine109.jpg       shine\n",
      "8    dataset2/shine232.jpg       shine\n",
      "9    dataset2/cloudy90.jpg      cloudy \n",
      "\n",
      "\n",
      "Label Distribution in Validation Set:\n",
      "sunrise    0.316964\n",
      "cloudy     0.267857\n",
      "shine      0.223214\n",
      "rain       0.191964\n",
      "Name: Image label, dtype: float64 \n",
      "\n",
      "\n",
      "First 10 Rows of Validation Set:\n",
      "                 File path Image label\n",
      "0   dataset2/sunrise68.jpg     sunrise\n",
      "1     dataset2/shine17.jpg       shine\n",
      "2   dataset2/cloudy212.jpg      cloudy\n",
      "3    dataset2/cloudy56.jpg      cloudy\n",
      "4   dataset2/sunrise92.jpg     sunrise\n",
      "5  dataset2/sunrise270.jpg     sunrise\n",
      "6   dataset2/cloudy190.jpg      cloudy\n",
      "7   dataset2/cloudy157.jpg      cloudy\n",
      "8     dataset2/rain108.jpg        rain\n",
      "9    dataset2/shine157.jpg       shine \n",
      "\n",
      "\n",
      "Label Distribution in Test Set:\n",
      "sunrise    0.320000\n",
      "cloudy     0.266667\n",
      "shine      0.226667\n",
      "rain       0.186667\n",
      "Name: Image label, dtype: float64 \n",
      "\n",
      "\n",
      "First 10 Rows of Test Set:\n",
      "                 File path Image label\n",
      "0  dataset2/sunrise198.jpg     sunrise\n",
      "1     dataset2/shine81.jpg       shine\n",
      "2   dataset2/cloudy139.jpg      cloudy\n",
      "3     dataset2/rain132.jpg        rain\n",
      "4  dataset2/sunrise233.jpg     sunrise\n",
      "5      dataset2/rain72.jpg        rain\n",
      "6     dataset2/shine89.jpg       shine\n",
      "7   dataset2/cloudy291.jpg      cloudy\n",
      "8   dataset2/sunrise48.jpg     sunrise\n",
      "9  dataset2/sunrise130.jpg     sunrise \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the partitions from CSV files\n",
    "train_df = pd.read_csv('my_training.csv', header=None, names=['File path', 'Image label'])\n",
    "validation_df = pd.read_csv('my_validation.csv', header=None, names=['File path', 'Image label'])\n",
    "test_df = pd.read_csv('my_test.csv', header=None, names=['File path', 'Image label'])\n",
    "\n",
    "# Creating a function to show label distribution and our first 10 rows\n",
    "def display_info(df, partition_name):\n",
    "    print(f\"Label Distribution in {partition_name}:\")\n",
    "    print(df['Image label'].value_counts(normalize=True), '\\n'*2)  # Normalized count for distribution\n",
    "    \n",
    "    # first 10 row display\n",
    "    print(f\"First 10 Rows of {partition_name}:\")\n",
    "    print(df.head(10), '\\n'*2)  \n",
    "\n",
    "# Display the information for each partition\n",
    "display_info(train_df, 'Training Set')\n",
    "display_info(validation_df, 'Validation Set')\n",
    "display_info(test_df, 'Test Set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.5 Comparing Our Results with the Given Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0p0bHC1zfnF3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Distribution in Given Training Set:\n",
      "sunrise    0.327785\n",
      "cloudy     0.256082\n",
      "shine      0.227913\n",
      "rain       0.188220\n",
      "Name: Image label, dtype: float64 \n",
      "\n",
      "\n",
      "First 10 Rows of Given Training Set:\n",
      "                 File path Image label\n",
      "0    dataset2/shine137.jpg       shine\n",
      "1    dataset2/shine177.jpg       shine\n",
      "2    dataset2/cloudy87.jpg      cloudy\n",
      "3  dataset2/sunrise290.jpg     sunrise\n",
      "4     dataset2/shine88.jpg       shine\n",
      "5  dataset2/sunrise275.jpg     sunrise\n",
      "6    dataset2/cloudy40.jpg      cloudy\n",
      "7  dataset2/sunrise313.jpg     sunrise\n",
      "8    dataset2/cloudy56.jpg      cloudy\n",
      "9   dataset2/cloudy250.jpg      cloudy \n",
      "\n",
      "\n",
      "Label Distribution in Given Validation Set:\n",
      "sunrise    0.305389\n",
      "cloudy     0.281437\n",
      "shine      0.227545\n",
      "rain       0.185629\n",
      "Name: Image label, dtype: float64 \n",
      "\n",
      "\n",
      "First 10 Rows of Given Validation Set:\n",
      "                 File path Image label\n",
      "0     dataset2/shine14.jpg       shine\n",
      "1    dataset2/cloudy47.jpg      cloudy\n",
      "2     dataset2/rain118.jpg        rain\n",
      "3  dataset2/sunrise228.jpg     sunrise\n",
      "4  dataset2/sunrise233.jpg     sunrise\n",
      "5     dataset2/rain201.jpg        rain\n",
      "6    dataset2/shine133.jpg       shine\n",
      "7    dataset2/cloudy64.jpg      cloudy\n",
      "8     dataset2/shine38.jpg       shine\n",
      "9   dataset2/cloudy181.jpg      cloudy \n",
      "\n",
      "\n",
      "Label Distribution in Given Test Set:\n",
      "cloudy     0.301775\n",
      "sunrise    0.289941\n",
      "shine      0.207101\n",
      "rain       0.201183\n",
      "Name: Image label, dtype: float64 \n",
      "\n",
      "\n",
      "First 10 Rows of Given Test Set:\n",
      "                 File path Image label\n",
      "0    dataset2/cloudy16.jpg      cloudy\n",
      "1    dataset2/shine202.jpg       shine\n",
      "2      dataset2/rain78.jpg        rain\n",
      "3   dataset2/cloudy212.jpg      cloudy\n",
      "4      dataset2/rain50.jpg        rain\n",
      "5   dataset2/cloudy144.jpg      cloudy\n",
      "6  dataset2/sunrise221.jpg     sunrise\n",
      "7     dataset2/rain134.jpg        rain\n",
      "8    dataset2/shine134.jpg       shine\n",
      "9     dataset2/rain209.jpg        rain \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv', header=None, names=['File path', 'Image label'])\n",
    "df_train = pd.read_csv('training.csv', header=None, names=['File path', 'Image label'])\n",
    "df_val = pd.read_csv('validation.csv', header=None, names=['File path', 'Image label'])\n",
    "\n",
    "display_info(df_train, 'Given Training Set')\n",
    "display_info(df_val , 'Given Validation Set')\n",
    "display_info(df_test, 'Given Test Set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both datasets and distributions look reasonably similar.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - preprocessing and preparation\n",
    "\n",
    "I'll use TensorFlow's TextLineDataset to create datasets for my training, validation, and test phases. My datasets will generate images that are resized to dimensions of 230 x 230 with 3 channels. Then normalized to fall within the range of 0 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Encoding our data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define and use `encode_labels` function to read a CSV file containing image paths and their corresponding textual labels, replace these textual labels with numeric codes based on a predefined dictionary `label_to_index`, and save the results to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_index = {'cloudy': 0, 'rain': 1, 'sunrise': 2, 'shine': 3}\n",
    "\n",
    "#function to encode labels from CSV\n",
    "def encode_labels(csv_file_path, output_file_path):\n",
    "    # Open input CSV for reading ('r') and output for writing ('w').\n",
    "    with open(csv_file_path, 'r') as infile, open(output_file_path, 'w') as outfile:\n",
    "        reader = csv.reader(infile)\n",
    "        writer = csv.writer(outfile)\n",
    "        for row in reader:\n",
    "\n",
    "            # Use the dictionary 'label_to_index' to find the encoded value, -1 if not found            \n",
    "            writer.writerow([row[0], label_to_index.get(row[1], -1)])\n",
    "\n",
    "\n",
    "encode_labels('training.csv', 'training_encoded.csv')\n",
    "encode_labels('validation.csv', 'validation_encoded.csv')\n",
    "encode_labels('test.csv', 'test_encoded.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we sequence functions for loading and preprocessing our image dataset within a TensorFlow pipeline. The workflow involves reading image paths and labels from CSV files, decoding and processing images, and preparing TensorFlow datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Resizing, normalizing, parsing, and decoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def parse_image_and_label(line):\n",
    "    parts = tf.strings.split(line, ',')\n",
    "    image = tf.io.read_file(parts[0])  # Read the image from the path -> first column -> part[0].\n",
    "    image = tf.image.decode_jpeg(image, channels=3) #Decode into a RGB\n",
    "    image = tf.image.resize(image, [230, 230]) # Resize into 230x230 \n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    \n",
    "    # ensures that the label is treated as a numeric type by converting string -> 32-bit int\n",
    "    label = tf.strings.to_number(parts[1], tf.int32)\n",
    "    return image, label\n",
    "\n",
    "def load_dataset(file_path):\n",
    "    dataset = tf.data.TextLineDataset(file_path)\n",
    "    #instructs TensorFlow to autodetermine  optimal threads to use for parallelizing the map function. \n",
    "    dataset = dataset.map(parse_image_and_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Creating the datasets\n",
    "training_dataset = load_dataset('training_encoded.csv')\n",
    "validation_dataset = load_dataset('validation_encoded.csv')\n",
    "test_dataset = load_dataset('test_encoded.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, `training_dataset`, `validation_dataset`, and `test_dataset` are ready to be used for model training and evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJMFW8x2fnF5"
   },
   "source": [
    "## A simple classifier\n",
    "\n",
    "### 2.1 First classifier\n",
    "\n",
    "I'll start by designing a basic model that includes:\n",
    "- A Flatten layer \n",
    "- An output layer configured with the appropriate size and activation function for our classification task. \n",
    "\n",
    "After setting up the model, I'll proceed to train it using the training data. hroughout the training process, I'll utilize the validation data to decide when it's optimal to stop training, ensuring the model doesn't overfit. Once the training is complete, I'll evaluate the trained model's performance on the test data and share the accuracy achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Simple Model Compiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple neural network serves as a baseline model to evaluate performance before moving on to more complex architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_simple = tf.keras.Sequential([\n",
    "    # Adding layers\n",
    "    tf.keras.layers.Flatten(input_shape=(230, 230, 3)),\n",
    "    tf.keras.layers.Dense(4, activation='softmax') # predicts one of four classes\n",
    "])\n",
    "\n",
    "\n",
    "model_simple.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy', #labels are integers -> sparse_categorical_crossentropy\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "early_stopping_simple = EarlyStopping(\n",
    "    monitor='val_loss', # Monitor validation loss\n",
    "    patience=3,         # Number of epochs with no improvement after which training will be stopped\n",
    "    verbose = 1,        # Show logs\n",
    "    restore_best_weights=True # Restores model weights from the epoch with the best value of the monitored metric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "      1/Unknown - 0s 120ms/step - loss: 1.4758 - accuracy: 0.1562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 18:15:50.466675: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-04-05 18:15:50.478947: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     22/Unknown - 0s 15ms/step - loss: 59.4619 - accuracy: 0.4205"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 18:15:51.158557: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 32ms/step - loss: 57.1350 - accuracy: 0.4264 - val_loss: 10.9868 - val_accuracy: 0.6467\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 23.4487 - accuracy: 0.5980 - val_loss: 13.7642 - val_accuracy: 0.6168\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 24.4147 - accuracy: 0.5762 - val_loss: 16.3793 - val_accuracy: 0.5868\n",
      "Epoch 4/100\n",
      "20/25 [=======================>......] - ETA: 0s - loss: 17.9699 - accuracy: 0.6562Restoring model weights from the end of the best epoch: 1.\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 22.1682 - accuracy: 0.6287 - val_loss: 13.4713 - val_accuracy: 0.6228\n",
      "Epoch 4: early stopping\n"
     ]
    }
   ],
   "source": [
    "simple_history = model_simple.fit(training_dataset,\n",
    "                    epochs=100,  # early stopping will prevent it from reaching this\n",
    "                    validation_data=validation_dataset,\n",
    "                    callbacks=[early_stopping_simple])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Simple Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 13ms/step - loss: 12.2706 - accuracy: 0.6154\n",
      "Test Loss: 12.27064323425293\n",
      "\n",
      "Test accuracy: 61.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 18:15:54.813915: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the test dataset\n",
    "test_loss_simple, test_acc_simple = model_simple.evaluate(test_dataset)\n",
    "\n",
    "print(f\"Test Loss: {test_loss_simple}\")\n",
    "print(f'\\nTest accuracy: {test_acc_simple*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7x5pFFXfnF6"
   },
   "source": [
    "### 2.2 A more complex classifier\n",
    "I'll experiment with a more intricate architecture, incorporating one or more hidden layers along with dropout regularization. To streamline this process and optimize the architecture, I'll employ keras-tuner. I'll explore various parameters, including the number and sizes of hidden layers, dropout rates, and learning rates. By tuning these parameters, I aim to find the configuration that yields the best performance for our task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Complex Model Compiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set up a more complex and configurable neural network architecture for hyperparameter tuning using TensorFlow's Keras API and the Keras Tuner. It dynamically adjusts the model's architecture and parameters based on the performance on a validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zHw8Ei04fnF7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 46s]\n",
      "val_accuracy: 0.78742516040802\n",
      "\n",
      "Best val_accuracy So Far: 0.814371258020401\n",
      "Total elapsed time: 00h 04m 52s\n"
     ]
    }
   ],
   "source": [
    "def hypermodel(hp):\n",
    "    model = tf.keras.Sequential([\n",
    "        Flatten(input_shape=(230, 230, 3))\n",
    "    ])\n",
    "    \n",
    "    for i in range(hp.Int('num_hidden_layers', 1, 4)):\n",
    "        model.add(Dense(\n",
    "            units=hp.Int(f'units_{i}', min_value=32, max_value=256, step=32),\n",
    "            activation='relu'\n",
    "        ))\n",
    "        model.add(Dropout(rate=hp.Float(f'dropout_{i}', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'rmsprop', 'sgd'])\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "    \n",
    "    # Using legacy optimizers for compatibility with M1/M2 Macs\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_choice == 'rmsprop':\n",
    "        optimizer = tf.keras.optimizers.legacy.RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer_choice == 'sgd':\n",
    "        optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10, \n",
    "    executions_per_trial=2,  # Performing 2 executions per trial\n",
    "    directory='my_dir',\n",
    "    project_name='complex_model_tuning'\n",
    ")\n",
    "\n",
    "early_stopping_complex = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "tuner.search(training_dataset,\n",
    "             epochs=100, \n",
    "             validation_data=validation_dataset,\n",
    "             callbacks=[early_stopping_complex],\n",
    "             verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Retrieving the best set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hidden layers: 1\n",
      "Hidden layer 1 size: 256\n",
      "Dropout rate for layer 1: 0.1\n",
      "Optimizer: sgd\n",
      "Learning rate: 0.00483404618006194\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "model_complex_final = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Details of the best hyperparameters\n",
    "num_hidden_layers = best_hps.get('num_hidden_layers')\n",
    "print(f\"Number of hidden layers: {num_hidden_layers}\")\n",
    "\n",
    "for i in range(num_hidden_layers):\n",
    "    print(f\"Hidden layer {i+1} size: {best_hps.get(f'units_{i}')}\")\n",
    "    print(f\"Dropout rate for layer {i+1}: {best_hps.get(f'dropout_{i}')}\")\n",
    "    \n",
    "optimizer_choice = best_hps.get('optimizer')\n",
    "learning_rate = best_hps.get('learning_rate')\n",
    "print(f\"Optimizer: {optimizer_choice}\")\n",
    "print(f\"Learning rate: {learning_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Building & Training the Best Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 2s 57ms/step - loss: 3.4603 - accuracy: 0.4277 - val_loss: 0.9035 - val_accuracy: 0.6168\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.9124 - accuracy: 0.6133 - val_loss: 0.7915 - val_accuracy: 0.7126\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.8054 - accuracy: 0.6543 - val_loss: 0.7420 - val_accuracy: 0.6407\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.7251 - accuracy: 0.6825 - val_loss: 0.7105 - val_accuracy: 0.6826\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 1s 56ms/step - loss: 0.6651 - accuracy: 0.7234 - val_loss: 0.6225 - val_accuracy: 0.7844\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.6239 - accuracy: 0.7388 - val_loss: 0.6059 - val_accuracy: 0.7725\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.6168 - accuracy: 0.7580 - val_loss: 0.5914 - val_accuracy: 0.8024\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 1s 52ms/step - loss: 0.5817 - accuracy: 0.7593 - val_loss: 0.5979 - val_accuracy: 0.8024\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 0.5558 - accuracy: 0.7772 - val_loss: 0.6025 - val_accuracy: 0.7964\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 2s 66ms/step - loss: 0.5344 - accuracy: 0.7810 - val_loss: 0.5725 - val_accuracy: 0.8084\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 2s 60ms/step - loss: 0.5272 - accuracy: 0.7759 - val_loss: 0.6290 - val_accuracy: 0.7425\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 0.5242 - accuracy: 0.7823 - val_loss: 0.6185 - val_accuracy: 0.7784\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.4932 - accuracy: 0.7964Restoring model weights from the end of the best epoch: 10.\n",
      "25/25 [==============================] - 1s 56ms/step - loss: 0.4932 - accuracy: 0.7964 - val_loss: 0.5983 - val_accuracy: 0.7964\n",
      "Epoch 13: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Training the complex model\n",
    "complex_history = model_complex_final.fit(\n",
    "    training_dataset,\n",
    "    epochs=100,  # EarlyStopping can stop it earlier\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=[early_stopping_complex]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Test Results of Our Complex Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4786 - accuracy: 0.8462\n",
      "Test Loss: 0.4786064624786377\n",
      "Test accuracy: 84.62%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the test dataset\n",
    "test_loss_complex, test_accuracy_complex = model_complex_final.evaluate(test_dataset)\n",
    "\n",
    "print(f\"Test Loss: {test_loss_complex}\")\n",
    "print(f'Test accuracy: {test_accuracy_complex*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write text below where you explain and justify your decision choices made in this task.\n",
    "\n",
    "(write your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5 Explaining Decision Choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71dBL-k0fnF8"
   },
   "source": [
    "In the process of designing the second model architecture I used `keras-tuner` to optimize hyperparameters\n",
    "\n",
    "- **Number of Hidden Layers**:\n",
    "\n",
    "Allowed the tuner to select between 1 and 4 hidden layers as adding hidden layers to neural networks can  increase  capacity to learn more patterns in the data. However, too many layers can lead to overfitting. A range of 1 to 4 layers is a moderate choice here.\n",
    "\n",
    "- **Sizes of Hidden Layers**:\n",
    "\n",
    "For each layer, the number of units ranges from 32 to 256, with a step of 32. This range allows the model to explore various sizes of layers to understand how much capacity (number of neurons) is needed in each layer to learn the patterns in the data effectively.\n",
    "\n",
    "- **Dropout Rate**:\n",
    "\n",
    "The dropout rate for each layer ranges from 0.1 to 0.5, with a step of 0.1. This range is chosen to find a sweet spot where the model is regularized enough to generalize well but not too much to underfit by losing significant information.\n",
    "\n",
    "- **Optimizer:**\n",
    "\n",
    "The choice among `adam`, `rmsprop`, and `sgd` covers a broad spectrum of optimization algorithms, from adaptive learning rate methods (adam and rmsprop) to a more classical approach (sgd). This allows the tuning process to evaluate both the efficiency and effectiveness of different types of optimizers in the model's training process.\n",
    "**(With help of generative AI)**\n",
    "\n",
    "- **Learning Rate:** \n",
    "The learning rate varies between 1e-4 and 1e-2 with logarithmic sampling. The learning rate is crucial for convergence during training; too high can cause the model to oscillate or diverge, too low might lead to a long training process **(With help of generative AI)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsM7wXbIfnF9"
   },
   "source": [
    "### 2.3 Error analysis\n",
    "\n",
    "Evaluating best-performing system\n",
    "\n",
    "1. Which system had a better accuracy on the test data?\n",
    "2. Which system had a lower degree of overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- The complex model achieved a test accuracy of **84.62%**, which is much higher than the simple model, which had a test accuracy of **61.54%**. This indicates that the complex model was able to learn more effectively from the training data and generalize better to the unseen test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- To evaluate the degree of overfitting, we look at the gap between training accuracy (or loss) and validation accuracy (or loss) during the training process. A smaller gap indicates a lower degree of overfitting.\n",
    "\n",
    "- **Complex Model:** The best validation accuracy was **80.84% (Epoch 10)**, and the training accuracy at that point was approximately **78.10%**. The gap between training and validation accuracy is relatively small, suggesting a lower degree of overfitting. Additionally, the early stopping callback terminated training at Epoch 13 due to a lack of improvement in validation loss, further helping to prevent overfitting.\n",
    "\n",
    "- **Simple Model:** The best validation accuracy was **64.67% (Epoch 1)**, with the training accuracy around **42.64%**. The initial gap suggests a mismatch in performance, but this seems more like the model was not adequately learning rather than overfitting. Given the overall lower accuracy scores and the erratic behavior of the model's loss and accuracy, it's challenging to directly compare overfitting in the traditional sense. However, the simple model's training was stopped early at Epoch 4, indicating it wasn't able to improve significantly after the first epoch.\n",
    "\n",
    "- **Conclusion:**\n",
    "The complex model outperformed simple model on the test set but also showed signs of effective learning and generalization with a lower degree of overfitting compared to the simple model.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJgTJjhUfnF9"
   },
   "source": [
    "## 3 - A more complex classifier\n",
    "\n",
    "### 3.1 Using ConvNets\n",
    "\n",
    "Implement a model that uses a sequence of at least two `ConvD`, each one followed with `MaxPooling2D`. Use reasonable numbers for the hyperparameters (number of filters, kernel size, pool size, activation, etc), base on what we have seen in the lectures. Feel free to research the internet and / or generative AI to help you find a reasonable choice of hyperparameters. For this task, do not use pre-trained models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Compiling CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we find the best hyperparameters for the CNN model defined in the `build_model` function using the Keras Tuner library's Random Search algorithm. By tuning hyperparameters such as filter sizes, kernel sizes, pool sizes, dense layer units, and optimizer choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "tvZQQPSJfnF-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 12m 28s]\n",
      "val_accuracy: 0.901197612285614\n",
      "\n",
      "Best val_accuracy So Far: 0.901197612285614\n",
      "Total elapsed time: 00h 45m 35s\n",
      "Best Hyperparameters:\n",
      "filters_1: 128\n",
      "kernel_size_1: 3\n",
      "pool_size_1: 3\n",
      "filters_2: 128\n",
      "kernel_size_2: 5\n",
      "pool_size_2: 2\n",
      "dense_units: 256\n",
      "optimizer: adam\n"
     ]
    }
   ],
   "source": [
    "def build_model(hp):\n",
    "    Convmodel = Sequential([\n",
    "        #2D convolution layer as the first layer, with tunable number of filters\n",
    "        Conv2D(filters=hp.Int('filters_1', min_value=32, max_value=128, step=32),\n",
    "               # The kernel sizecan be either 3x3 or 5x5, decided by the tuner (Use of Generative AI)\n",
    "               kernel_size=hp.Choice('kernel_size_1', values=[3, 5]),\n",
    "               activation='relu', input_shape=(230, 230, 3)),\n",
    "        \n",
    "        # Pool size that can either be 2x2 or 3x3 (Use of Generative AI)\n",
    "        MaxPooling2D(pool_size=hp.Choice('pool_size_1', values=[2, 3])),\n",
    "        \n",
    "        Conv2D(filters=hp.Int('filters_2', min_value=64, max_value=256, step=32),\n",
    "               kernel_size=hp.Choice('kernel_size_2', values=[3, 5]),\n",
    "               activation='relu'),\n",
    "        MaxPooling2D(pool_size=hp.Choice('pool_size_2', values=[2, 3])),\n",
    "        \n",
    "        #Flattens the input to transition to dense layers\n",
    "        Flatten(),\n",
    "        Dense(hp.Int('dense_units', min_value=128, max_value=512, step=128), activation='relu'),\n",
    "        Dense(4, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    Convmodel.compile(optimizer=hp.Choice('optimizer', values=['rmsprop', 'adam']),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return Convmodel\n",
    "\n",
    "early_stopping_conv = EarlyStopping(\n",
    "    monitor='val_loss', # Monitor validation loss\n",
    "    patience=3,         # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True # Restores model weights from the epoch with the best value of the monitored metric\n",
    ")\n",
    "\n",
    "# Initialize the tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=1,\n",
    "    directory='my_dir',\n",
    "    project_name='hparam_tuning'\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    training_dataset,\n",
    "    epochs=10,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=[early_stopping_conv]\n",
    ")\n",
    "\n",
    "# Retrieve the best model and hyperparameters\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "\n",
    "print(\"Best Hyperparameters:\")\n",
    "for hyperparam, value in best_hyperparameters.values.items():\n",
    "    print(f\"{hyperparam}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Training Our CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 39s 2s/step - loss: 0.1147 - accuracy: 0.9654 - val_loss: 1.0516 - val_accuracy: 0.7964\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 39s 2s/step - loss: 0.1495 - accuracy: 0.9462 - val_loss: 0.8195 - val_accuracy: 0.8563\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 39s 2s/step - loss: 0.1716 - accuracy: 0.9449 - val_loss: 0.8479 - val_accuracy: 0.8263\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 43s 2s/step - loss: 0.1095 - accuracy: 0.9590 - val_loss: 1.3887 - val_accuracy: 0.7665\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 44s 2s/step - loss: 0.1051 - accuracy: 0.9526 - val_loss: 0.7719 - val_accuracy: 0.8743\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 44s 2s/step - loss: 0.1102 - accuracy: 0.9565 - val_loss: 0.6297 - val_accuracy: 0.9042\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 44s 2s/step - loss: 0.0390 - accuracy: 0.9898 - val_loss: 0.7534 - val_accuracy: 0.8862\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 40s 2s/step - loss: 0.0225 - accuracy: 0.9923 - val_loss: 0.7796 - val_accuracy: 0.8922\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 42s 2s/step - loss: 0.0191 - accuracy: 0.9936 - val_loss: 0.8099 - val_accuracy: 0.9042\n"
     ]
    }
   ],
   "source": [
    "history_cnn = best_model.fit(\n",
    "    training_dataset,\n",
    "    epochs=100,  # Higher epoch limit; early stopping will prevent reaching this if not necessary\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=[early_stopping_conv]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 CNN Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 445ms/step - loss: 0.2420 - accuracy: 0.9112\n",
      "Test Loss: 0.24201205372810364\n",
      "Test accuracy: 91.12%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the test dataset\n",
    "test_loss_conv, test_accuracy_conv = best_model.evaluate(test_dataset)\n",
    "\n",
    "print(f\"Test Loss: {test_loss_conv}\")\n",
    "print(f'Test accuracy: {test_accuracy_conv*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "152E3mgdfnF_"
   },
   "source": [
    "### 3.2 Using pre-trained models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 MobileNet Model Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "FOeToHlyfnF_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 230, 230, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 115, 115, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 115, 115, 32  128         ['Conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 115, 115, 32  0           ['bn_Conv1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 115, 115, 32  288        ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                    )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 115, 115, 32  128        ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)              )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 115, 115, 32  0          ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                          )                                ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 115, 115, 16  512        ['expanded_conv_depthwise_relu[0]\n",
      "                                )                                [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 115, 115, 16  64         ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 115, 115, 96  1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 115, 115, 96  384        ['block_1_expand[0][0]']         \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 115, 115, 96  0           ['block_1_expand_BN[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 117, 117, 96  0           ['block_1_expand_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 58, 58, 96)  864         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 58, 58, 96)  384         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 58, 58, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 58, 58, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 58, 58, 24)  96          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 58, 58, 144)  3456        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 58, 58, 144)  576        ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 58, 58, 144)  0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 58, 58, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 58, 58, 144)  576        ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 58, 58, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 58, 58, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 58, 58, 24)  96          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 58, 58, 24)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 58, 58, 144)  3456        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 58, 58, 144)  576        ['block_3_expand[0][0]']         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)     (None, 58, 58, 144)  0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 59, 59, 144)  0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 29, 29, 144)  1296       ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 29, 29, 144)  576        ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 29, 29, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 29, 29, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 29, 29, 32)  128         ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 29, 29, 192)  6144        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 29, 29, 192)  768        ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 29, 29, 192)  0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 29, 29, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 29, 29, 192)  768        ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 29, 29, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 29, 29, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 29, 29, 32)  128         ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 29, 29, 32)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 29, 29, 192)  6144        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 29, 29, 192)  768        ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 29, 29, 192)  0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 29, 29, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 29, 29, 192)  768        ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 29, 29, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 29, 29, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 29, 29, 32)  128         ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 29, 29, 32)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 29, 29, 192)  6144        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 29, 29, 192)  768        ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 29, 29, 192)  0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 31, 31, 192)  0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 15, 15, 192)  1728       ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 15, 15, 192)  768        ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 15, 15, 192)  0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 15, 15, 64)   12288       ['block_6_depthwise_relu[0][0]'] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 15, 15, 64)  256         ['block_6_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 15, 15, 384)  24576       ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 15, 15, 384)  1536       ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 15, 15, 384)  0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 15, 15, 384)  3456       ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 15, 15, 384)  1536       ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 15, 15, 384)  0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 15, 15, 64)   24576       ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 15, 15, 64)  256         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 15, 15, 64)   0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 15, 15, 384)  24576       ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 15, 15, 384)  1536       ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 15, 15, 384)  0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 15, 15, 384)  3456       ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 15, 15, 384)  1536       ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 15, 15, 384)  0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 15, 15, 64)   24576       ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 15, 15, 64)  256         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 15, 15, 64)   0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 15, 15, 384)  24576       ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 15, 15, 384)  1536       ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 15, 15, 384)  0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 15, 15, 384)  3456       ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 15, 15, 384)  1536       ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 15, 15, 384)  0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 15, 15, 64)   24576       ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 15, 15, 64)  256         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 15, 15, 64)   0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 15, 15, 384)  24576       ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 15, 15, 384)  1536       ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 15, 15, 384)  0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 15, 15, 384)  3456       ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block_10_depthwise_BN (BatchNo  (None, 15, 15, 384)  1536       ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 15, 15, 384)  0          ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 15, 15, 96)   36864       ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 15, 15, 96)  384         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 15, 15, 576)  55296       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 15, 15, 576)  2304       ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 15, 15, 576)  0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 15, 15, 576)  5184       ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 15, 15, 576)  2304       ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 15, 15, 576)  0          ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 15, 15, 96)   55296       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 15, 15, 96)  384         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 15, 15, 96)   0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 15, 15, 576)  55296       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 15, 15, 576)  2304       ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 15, 15, 576)  0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 15, 15, 576)  5184       ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 15, 15, 576)  2304       ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 15, 15, 576)  0          ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 15, 15, 96)   55296       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 15, 15, 96)  384         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 15, 15, 96)   0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 15, 15, 576)  55296       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 15, 15, 576)  2304       ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 15, 15, 576)  0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 17, 17, 576)  0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 8, 8, 576)   5184        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 8, 8, 576)   2304        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 8, 8, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 8, 8, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 8, 8, 160)   640         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 8, 8, 960)    153600      ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 8, 8, 960)   3840        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block_14_expand_relu (ReLU)    (None, 8, 8, 960)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_14_depthwise (DepthwiseC  (None, 8, 8, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 8, 8, 960)   3840        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 8, 8, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 8, 8, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 8, 8, 160)   640         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 8, 8, 160)    0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 8, 8, 960)    153600      ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 8, 8, 960)   3840        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 8, 8, 960)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 8, 8, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 8, 8, 960)   3840        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 8, 8, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 8, 8, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 8, 8, 160)   640         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 8, 8, 160)    0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 8, 8, 960)    153600      ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 8, 8, 960)   3840        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 8, 8, 960)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 8, 8, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 8, 8, 960)   3840        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 8, 8, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 8, 8, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 8, 8, 320)   1280        ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 8, 8, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 8, 8, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 8, 8, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 1280)        0           ['out_relu[0][0]']               \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1024)         1311744     ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 4)            4100        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,573,828\n",
      "Trainable params: 1,315,844\n",
      "Non-trainable params: 2,257,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Loading MobileNetV2 with pre-trained ImageNet weights, excluding the top (classification) layer\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(230, 230, 3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "# Freeze the layers of the base_model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create the custom head for our dataset (replacing the top layer of MobileNet)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)  # Add a global spatial average pooling layer\n",
    "x = Dense(1024, activation='relu')(x)  # Add a fully-connected layer\n",
    "predictions = Dense(4, activation='softmax')(x)  # Add the final classification layer\n",
    "\n",
    "# Construct the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Learning rate schedule (Use of Generative AI)\n",
    "initial_learning_rate = 0.0001\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "\n",
    "\n",
    "# Use the legacy version of the Adam optimizer for better performance on M1/M2 Macs (Use of Generative AI)\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# Compile the model with the modified optimizer\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 MobileNet Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 7s 269ms/step - loss: 0.8008 - accuracy: 0.7145 - val_loss: 0.4453 - val_accuracy: 0.9102\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 6s 249ms/step - loss: 0.2926 - accuracy: 0.9475 - val_loss: 0.3056 - val_accuracy: 0.9162\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 6s 257ms/step - loss: 0.1868 - accuracy: 0.9706 - val_loss: 0.2547 - val_accuracy: 0.9341\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 6s 255ms/step - loss: 0.1377 - accuracy: 0.9808 - val_loss: 0.2269 - val_accuracy: 0.9341\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 6s 260ms/step - loss: 0.1080 - accuracy: 0.9821 - val_loss: 0.2079 - val_accuracy: 0.9341\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 6s 253ms/step - loss: 0.0874 - accuracy: 0.9846 - val_loss: 0.1953 - val_accuracy: 0.9341\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 6s 248ms/step - loss: 0.0723 - accuracy: 0.9872 - val_loss: 0.1866 - val_accuracy: 0.9401\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 6s 246ms/step - loss: 0.0610 - accuracy: 0.9910 - val_loss: 0.1793 - val_accuracy: 0.9401\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 6s 242ms/step - loss: 0.0521 - accuracy: 0.9962 - val_loss: 0.1729 - val_accuracy: 0.9461\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 6s 247ms/step - loss: 0.0451 - accuracy: 0.9974 - val_loss: 0.1675 - val_accuracy: 0.9521\n"
     ]
    }
   ],
   "source": [
    "history_mobilenet = model.fit(\n",
    "    training_dataset,\n",
    "    epochs=10,\n",
    "    validation_data=validation_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 MobileNet Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 173ms/step - loss: 0.1081 - accuracy: 0.9645\n",
      "Test Loss: 0.10806741565465927\n",
      "Test accuracy: 96.45%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the test dataset\n",
    "test_loss_mobilenet, test_accuracy_mobilenet = model.evaluate(test_dataset)\n",
    "\n",
    "print(f\"Test Loss: {test_loss_mobilenet}\")\n",
    "print(f'Test accuracy: {test_accuracy_mobilenet*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sb0NTIk1fnGA"
   },
   "source": [
    "### Task 3.3 Comparative evaluation\n",
    "\n",
    "Analyzing and comparing the evaluation results of the top-performing systems\n",
    "\n",
    "- Among all the systems, which one performed the best on the test set?\n",
    "- Which type of weather was the most challenging to detect based on these accuracy scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mobilenet system performs better on the test set, achieving a test accuracy of **96.45%**, compared to the ConvModel system, which has a test accuracy of **91.12%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 Accuracy of your best system on each of the different weather categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 166ms/step\n",
      "Confusion Matrix:\n",
      "[[49  0  0  2]\n",
      " [ 0 34  0  0]\n",
      " [ 0  0 48  1]\n",
      " [ 2  0  1 32]]\n",
      "Accuracy for class 0 (Weather Condition): 96.08%\n",
      "Accuracy for class 1 (Weather Condition): 100.00%\n",
      "Accuracy for class 2 (Weather Condition): 97.96%\n",
      "Accuracy for class 3 (Weather Condition): 91.43%\n",
      "The most difficult to detect weather condition is class 3.\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_dataset)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "true_labels = np.concatenate([y for x, y in test_dataset], axis=0)\n",
    "\n",
    "# confusion matrix\n",
    "conf_matrix = tf.math.confusion_matrix(true_labels, predicted_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix.numpy())\n",
    "\n",
    "# accuracy for each class\n",
    "class_accuracies = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "for i, acc in enumerate(class_accuracies):\n",
    "    print(f\"Accuracy for class {i} (Weather Condition): {acc*100:.2f}%\")\n",
    "\n",
    "most_difficult_weather = np.argmin(class_accuracies)\n",
    "print(f\"The most difficult to detect weather condition is class {most_difficult_weather}.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
